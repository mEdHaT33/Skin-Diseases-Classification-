{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *`Watermark Mask`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "def process(img):\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img_blur = cv2.GaussianBlur(img_gray, (3, 3), 0)\n",
    "    img_canny = cv2.Canny(img_blur, 180, 60)\n",
    "    img_dilate = cv2.dilate(img_canny, None, iterations=1)\n",
    "    return cv2.erode(img_dilate, None, iterations=1)\n",
    "\n",
    "def get_watermark(img):\n",
    "    contours, _ = cv2.findContours(process(img), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    img.fill(255)\n",
    "    for cnt in contours:\n",
    "        if cv2.contourArea(cnt) > 100:\n",
    "            cv2.drawContours(img, [cnt], -1, 0, -1)\n",
    "\n",
    "img = cv2.imread(\"cwatermark.jpg\")\n",
    "get_watermark(img)\n",
    "img = cv2.bitwise_not(img)\n",
    "cv2.imshow(\"Watermark\", img)\n",
    "cv2.imwrite(\"mask.jpg\", img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"input.jpg\")\n",
    "mask = cv2.imread('Fmask.jpg')\n",
    "mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "dilatekernel = np.ones((4, 4), 'uint8')\n",
    "mask = cv2.dilate(mask, dilatekernel)\n",
    "out = cv2.inpaint(img, mask, 6, flags= cv2.INPAINT_TELEA)\n",
    "#cv2.imshow(\"Input\", img)\n",
    "#cv2.imshow(\"Watermark\", mask)\n",
    "cv2.imshow(\"Output\", out)\n",
    "cv2.imwrite(\"no_wm.jpg\", out)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read input image and mask\n",
    "img = cv2.imread(\"input.jpg\")\n",
    "mask = cv2.imread('Fmask.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Dilate the mask\n",
    "dilate_kernel = np.ones((7, 7), np.uint8)\n",
    "mask_dilated = cv2.dilate(mask, dilate_kernel)\n",
    "\n",
    "# Inpainting\n",
    "out = cv2.inpaint(img, mask, 25, flags=cv2.INPAINT_TELEA)\n",
    "\n",
    "# Apply filters to enhance the output\n",
    "out = cv2.medianBlur(out, 9)  # Median filter\n",
    "out = cv2.morphologyEx(out, cv2.MORPH_CLOSE, np.ones((9, 9), np.uint8))  # Closing operation\n",
    "\n",
    "# Sharpening the inpainted region using unsharp masking\n",
    "sharpness = 0.5 # Adjust the sharpness factor according to your preference\n",
    "blurred = cv2.GaussianBlur(out, (0, 0), 3)\n",
    "sharpened = cv2.addWeighted(out, 1. + sharpness, blurred, -sharpness, 0)\n",
    "\n",
    "# Apply the sharpened region to the original image using the mask\n",
    "result = img.copy()\n",
    "result[mask_dilated != 0] = sharpened[mask_dilated != 0]\n",
    "\n",
    "# Display output\n",
    "cv2.imshow(\"Output\", result)\n",
    "cv2.imwrite(\"no_wm1.jpg\", result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read input and mask images\n",
    "img = cv2.imread(\"input.jpg\")\n",
    "mask = cv2.imread('mask.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Create a black canvas with the same dimensions as the input image\n",
    "black_canvas = np.zeros_like(img)\n",
    "\n",
    "# Calculate the position to place the mask at the center of the canvas\n",
    "x_offset = (black_canvas.shape[1] - mask.shape[1]) // 2\n",
    "y_offset = (black_canvas.shape[0] - mask.shape[0]) // 2\n",
    "\n",
    "# Expand the dimensions of the mask to match the number of channels in the black canvas\n",
    "expanded_mask = np.expand_dims(mask, axis=-1)\n",
    "expanded_mask = np.repeat(expanded_mask, 3, axis=-1)\n",
    "\n",
    "# Place the mask at the center of the black canvas\n",
    "black_canvas[y_offset:y_offset+mask.shape[0], x_offset:x_offset+mask.shape[1]] = expanded_mask\n",
    "\n",
    "# Convert the mask to 8-bit single-channel image\n",
    "dilated_mask = cv2.cvtColor(black_canvas, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Dilate the mask\n",
    "dilatekernel = np.ones((4, 4), 'uint8')\n",
    "dilated_mask = cv2.dilate(dilated_mask, dilatekernel)\n",
    "\n",
    "# Inpaint the input image using the dilated mask\n",
    "out = cv2.inpaint(img, dilated_mask, 7, flags=cv2.INPAINT_TELEA)\n",
    "\n",
    "# Display the output image\n",
    "cv2.imshow(\"Watermark\", dilated_mask)\n",
    "cv2.imshow(\"Output\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *`Watermark Removal`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def remove_watermark(input_path, output_path, mask_path):\n",
    "    img = cv2.imread(input_path)\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Create a black canvas with the same dimensions as the input image\n",
    "    black_canvas = np.zeros_like(img)\n",
    "\n",
    "    # Calculate the position to place the mask at the center of the canvas\n",
    "    x_offset = (black_canvas.shape[1] - mask.shape[1]) // 2\n",
    "    y_offset = (black_canvas.shape[0] - mask.shape[0]) // 2\n",
    "\n",
    "    # Expand the dimensions of the mask to match the number of channels in the black canvas\n",
    "    expanded_mask = np.expand_dims(mask, axis=-1)\n",
    "    expanded_mask = np.repeat(expanded_mask, 3, axis=-1)\n",
    "\n",
    "    # Place the mask at the center of the black canvas\n",
    "    black_canvas[y_offset:y_offset+mask.shape[0], x_offset:x_offset+mask.shape[1]] = expanded_mask\n",
    "\n",
    "    # Convert the mask to 8-bit single-channel image\n",
    "    dilated_mask = cv2.cvtColor(black_canvas, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Dilate the mask\n",
    "    dilatekernel = np.ones((4, 4), 'uint8')\n",
    "    dilated_mask = cv2.dilate(dilated_mask, dilatekernel)\n",
    "\n",
    "    # Inpaint the input image using the dilated mask\n",
    "    out = cv2.inpaint(img, dilated_mask, 7, flags=cv2.INPAINT_TELEA)\n",
    "    cv2.imwrite(output_path, out)\n",
    "\n",
    "# Directory paths\n",
    "old_dir = \"old\"\n",
    "cleaned_dir = \"cleaned_images\"\n",
    "mask_path = \"mask.jpg\"\n",
    "\n",
    "# Ensure cleaned images directory exists\n",
    "if not os.path.exists(cleaned_dir):\n",
    "    os.makedirs(cleaned_dir)\n",
    "\n",
    "# Iterate over each image in the old directory\n",
    "for filename in os.listdir(old_dir):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\") or filename.endswith(\".png\"):\n",
    "        input_path = os.path.join(old_dir, filename)\n",
    "        output_path = os.path.join(cleaned_dir, filename)\n",
    "        remove_watermark(input_path, output_path, mask_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *`Others`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m             cv2\u001b[38;5;241m.\u001b[39mdrawContours(img, [cnt], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     21\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwatermark.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 22\u001b[0m \u001b[43mget_watermark\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Inpainting to fill the removed regions\u001b[39;00m\n\u001b[0;32m     24\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39minpaint(img, (img \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m), inpaintRadius\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, flags\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mINPAINT_TELEA)\n",
      "Cell \u001b[1;32mIn[10], line 14\u001b[0m, in \u001b[0;36mget_watermark\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_watermark\u001b[39m(img):\n\u001b[1;32m---> 14\u001b[0m     contours, _ \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mfindContours(\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m, cv2\u001b[38;5;241m.\u001b[39mRETR_EXTERNAL, cv2\u001b[38;5;241m.\u001b[39mCHAIN_APPROX_SIMPLE)\n\u001b[0;32m     15\u001b[0m     img\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m255\u001b[39m)\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cnt \u001b[38;5;129;01min\u001b[39;00m contours:\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;66;03m# Refine contour filtering based on area and other properties\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[10], line 4\u001b[0m, in \u001b[0;36mprocess\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess\u001b[39m(img):\n\u001b[1;32m----> 4\u001b[0m     img_gray \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2GRAY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Apply adaptive thresholding\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     _, img_thresh \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mthreshold(img_gray, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mTHRESH_BINARY_INV \u001b[38;5;241m|\u001b[39m cv2\u001b[38;5;241m.\u001b[39mTHRESH_OTSU)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "def process(img):\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Apply adaptive thresholding\n",
    "    _, img_thresh = cv2.threshold(img_gray, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)\n",
    "    # Perform morphological operations\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    img_open = cv2.morphologyEx(img_thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "    img_close = cv2.morphologyEx(img_open, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "    return img_close\n",
    "\n",
    "def get_watermark(img):\n",
    "    contours, _ = cv2.findContours(process(img), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    img.fill(255)\n",
    "    for cnt in contours:\n",
    "        # Refine contour filtering based on area and other properties\n",
    "        if cv2.contourArea(cnt) > 100:\n",
    "            cv2.drawContours(img, [cnt], -1, 0, -1)\n",
    "\n",
    "img = cv2.imread(\"watermark.jpg\")\n",
    "get_watermark(img)\n",
    "# Inpainting to fill the removed regions\n",
    "img = cv2.inpaint(img, (img == 0).astype(int), inpaintRadius=3, flags=cv2.INPAINT_TELEA)\n",
    "cv2.imshow(\"Watermark Removed\", img)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def remove_watermark(img, template_path):\n",
    "    template = cv2.imread(template_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if template is None:\n",
    "        print(\"Error: Template image not found.\")\n",
    "        return img\n",
    "\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    h, w = template.shape[::-1]  # Get width and height of the template\n",
    "\n",
    "    res = cv2.matchTemplate(img_gray, template, cv2.TM_CCOEFF_NORMED)\n",
    "    threshold = 0.8\n",
    "    loc = np.where(res >= threshold)\n",
    "\n",
    "    # Debugging: Visualize matched regions\n",
    "    img_debug = img.copy()\n",
    "    for pt in zip(*loc[::-1]):\n",
    "        cv2.rectangle(img_debug, pt, (pt[0] + w, pt[1] + h), (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Debug: Matched Regions\", img_debug)\n",
    "    cv2.waitKey(0)w\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return img\n",
    "\n",
    "img = cv2.imread(\"input.jpg\")\n",
    "if img is None:\n",
    "    print(\"Error: Input image not found.\")\n",
    "else:\n",
    "    template_path = \"watermark.jpg\"\n",
    "    result = remove_watermark(img, template_path)\n",
    "\n",
    "    cv2.imshow(\"Watermark Removed\", result)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"input.jpg\")\n",
    "img2 = cv2.imread('Fwatermark.jpg')\n",
    "# remove watermark with mark\n",
    "img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "dilatekernel = np.ones((5, 5), 'uint8')\n",
    "img2 = cv2.dilate(img2, dilatekernel)\n",
    "out = cv2.inpaint(img, img2, 3, flags= cv2.INPAINT_NS)\n",
    "cv2.imshow(\"Input\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow(\"Watermark\", img2)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow(\"Output\", out)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def invert_mask(mask):\n",
    "    # Invert the mask by bitwise not operation\n",
    "    inverted_mask = cv2.bitwise_not(mask)\n",
    "    return inverted_mask\n",
    "\n",
    "# Load the mask\n",
    "mask = cv2.imread('watermark.jpg', 0)  # Read mask as grayscale\n",
    "\n",
    "# Invert the mask\n",
    "inverted_mask = invert_mask(mask)\n",
    "\n",
    "# Display or save the inverted mask\n",
    "cv2.imshow('Inverted Mask', inverted_mask)\n",
    "cv2.imwrite(\"Fwatermark.jpg\", inverted_mask)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def remove_watermark(image_path, mask_path):\n",
    "    # Load the image and the mask\n",
    "    image = cv2.imread(image_path)\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Convert the mask to binary (if needed)\n",
    "    _, mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Apply inpainting\n",
    "    result = cv2.inpaint(image, mask, inpaintRadius=3, flags=cv2.INPAINT_TELEA)\n",
    "\n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "image_path = 'input.jpg'\n",
    "mask_path = 'Fwatermark.jpg'\n",
    "output_image = remove_watermark(image_path, mask_path)\n",
    "cv2.imshow('Output Image', output_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_with_watermark.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     27\u001b[0m mask_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwatermark.png\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 28\u001b[0m output_image \u001b[38;5;241m=\u001b[39m \u001b[43mremove_watermark\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_without_watermark.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, output_image)\n",
      "Cell \u001b[1;32mIn[3], line 9\u001b[0m, in \u001b[0;36mremove_watermark\u001b[1;34m(image_path, mask_path)\u001b[0m\n\u001b[0;32m      6\u001b[0m mask \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(mask_path, cv2\u001b[38;5;241m.\u001b[39mIMREAD_GRAYSCALE)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Convert the image to grayscale\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m gray_image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2GRAY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Apply thresholding to the mask to get a binary mask\u001b[39;00m\n\u001b[0;32m     12\u001b[0m _, binary_mask \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mthreshold(mask, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m255\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mTHRESH_BINARY)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "def remove_watermark(image_path, mask_path):\n",
    "    # Load the image and the mask\n",
    "    image = cv2.imread(image_path)\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply thresholding to the mask to get a binary mask\n",
    "    _, binary_mask = cv2.threshold(mask, 200, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Invert the binary mask\n",
    "    inverted_mask = cv2.bitwise_not(binary_mask)\n",
    "\n",
    "    # Apply inpainting to the grayscale image using the inverted mask\n",
    "    inpainted_image = cv2.inpaint(gray_image, inverted_mask, inpaintRadius=3, flags=cv2.INPAINT_TELEA)\n",
    "\n",
    "    # Convert the inpainted image back to BGR\n",
    "    inpainted_image_bgr = cv2.cvtColor(inpainted_image, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    return inpainted_image_bgr\n",
    "\n",
    "# Example usage\n",
    "image_path = 'image_with_watermark.jpg'\n",
    "mask_path = 'watermark.png'\n",
    "output_image = remove_watermark(image_path, mask_path)\n",
    "cv2.imwrite('image_without_watermark.jpg', output_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "directory = \"old/\"\n",
    "image_files = os.listdir(directory)\n",
    "\n",
    "# Create a folder for the processed images (if it doesn't exist)\n",
    "output_folder = \"cleaned_images\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "def process_image(img):\n",
    "    \n",
    "    return new_img\n",
    "\n",
    "# Create a window to display images\n",
    "cv2.namedWindow('Images', cv2.WINDOW_NORMAL)\n",
    "\n",
    "# Iterate over each image file\n",
    "for image_file in image_files:\n",
    "    # Read the image\n",
    "    img = cv2.imread(os.path.join(directory, image_file))\n",
    "\n",
    "    # Process the image\n",
    "    processed_img = process_image(img)\n",
    "\n",
    "    # Concatenate the original and processed images horizontally\n",
    "    combined_image = np.hstack((img, processed_img))\n",
    "\n",
    "    # Display the combined image\n",
    "    cv2.imshow('Images', combined_image)\n",
    "    cv2.waitKey(0)  # Wait indefinitely until a key is pressed\n",
    "\n",
    "# Close the window after all images are displayed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TclError",
     "evalue": "image \"pyimage3\" doesn't exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTclError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 39\u001b[0m\n\u001b[0;32m     37\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mold/1.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     38\u001b[0m img1 \u001b[38;5;241m=\u001b[39m ImageTk\u001b[38;5;241m.\u001b[39mPhotoImage(Image\u001b[38;5;241m.\u001b[39mopen(path))\n\u001b[1;32m---> 39\u001b[0m panel \u001b[38;5;241m=\u001b[39m \u001b[43mtk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLabel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m panel\u001b[38;5;241m.\u001b[39mimage \u001b[38;5;241m=\u001b[39m img1  \u001b[38;5;66;03m# Retain reference to the image object\u001b[39;00m\n\u001b[0;32m     41\u001b[0m panel\u001b[38;5;241m.\u001b[39mplace(x\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m150\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m120\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Shiko\\miniconda3\\envs\\GPU\\lib\\tkinter\\__init__.py:3148\u001b[0m, in \u001b[0;36mLabel.__init__\u001b[1;34m(self, master, cnf, **kw)\u001b[0m\n\u001b[0;32m   3130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, master\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, cnf\u001b[38;5;241m=\u001b[39m{}, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[0;32m   3131\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Construct a label widget with the parent MASTER.\u001b[39;00m\n\u001b[0;32m   3132\u001b[0m \n\u001b[0;32m   3133\u001b[0m \u001b[38;5;124;03m    STANDARD OPTIONS\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3146\u001b[0m \n\u001b[0;32m   3147\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3148\u001b[0m     \u001b[43mWidget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaster\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcnf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Shiko\\miniconda3\\envs\\GPU\\lib\\tkinter\\__init__.py:2572\u001b[0m, in \u001b[0;36mBaseWidget.__init__\u001b[1;34m(self, master, widgetName, cnf, kw, extra)\u001b[0m\n\u001b[0;32m   2570\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m classes:\n\u001b[0;32m   2571\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m cnf[k]\n\u001b[1;32m-> 2572\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2573\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidgetName\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mextra\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_options\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcnf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2574\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m classes:\n\u001b[0;32m   2575\u001b[0m     k\u001b[38;5;241m.\u001b[39mconfigure(\u001b[38;5;28mself\u001b[39m, v)\n",
      "\u001b[1;31mTclError\u001b[0m: image \"pyimage3\" doesn't exist"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import ImageTk, Image\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, Button, messagebox\n",
    "\n",
    "# Function to open an image with OpenCV and display it in a Tkinter window\n",
    "def open_img():\n",
    "    global img_with_watermark, img_without_watermark\n",
    "    filename = filedialog.askopenfilename(title=\"Select file\")\n",
    "\n",
    "    img_with_watermark = cv2.imread(filename, 1)\n",
    "    cv2.imshow(\"Image With Watermark\", img_with_watermark)\n",
    "\n",
    "    img_without_watermark = cv2.imread(filename)\n",
    "    _, thresh = cv2.threshold(img_without_watermark, 150, 255, cv2.THRESH_BINARY)\n",
    "    cv2.imshow('Image Without Watermark', thresh)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Function to exit the application\n",
    "def exit_win():\n",
    "    if messagebox.askokcancel(\"Exit\", \"Do you want to exit?\"):\n",
    "        window.destroy()\n",
    "\n",
    "# Tkinter window setup\n",
    "window = tk.Tk()\n",
    "window.title(\"Image Watermark Remover\")\n",
    "window.geometry('1000x700')\n",
    "\n",
    "# Top label\n",
    "start1 = tk.Label(text=\"Image Watermark Remover\", font=(\"Arial\", 50), fg=\"magenta\")\n",
    "start1.place(x=80, y=10)\n",
    "\n",
    "# Image on the main window\n",
    "path = \"old/1.jpg\"\n",
    "img1 = ImageTk.PhotoImage(Image.open(path))\n",
    "panel = tk.Label(window, image=img1)\n",
    "panel.image = img1  # Retain reference to the image object\n",
    "panel.place(x=150, y=120)\n",
    "\n",
    "# Second image label\n",
    "sec1 = tk.Label(text=\"Select any image with Watermark & Remove it...\", font=(\"Arial\", 40), fg=\"green\")\n",
    "sec1.place(x=200, y=350)\n",
    "\n",
    "# Select Button\n",
    "selectb = Button(window, text=\"SELECT\", command=open_img, font=(\"Arial\", 25), bg=\"light green\", fg=\"blue\")\n",
    "selectb.place(x=150, y=550)\n",
    "\n",
    "# Exit Button\n",
    "exitb = Button(window, text=\"EXIT\", command=exit_win, font=(\"Arial\", 25), bg=\"red\", fg=\"blue\")\n",
    "exitb.place(x=700, y=550)\n",
    "\n",
    "window.protocol(\"WM_DELETE_WINDOW\", exit_win)\n",
    "window.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
